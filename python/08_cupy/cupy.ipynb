{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking NumPy and CuPy\n",
    "\n",
    "* CuPy is an open source library for GPU-accelerated computing with Python. It shares the same API set as NumPy and SciPy, allowing it to be a drop-in replacement to run NumPy/SciPy code on GPU.\n",
    "* \"Cu\" in CuPy stands for Nvidia's CUDA framework which allows program to perform general-purpose calculations on GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def generate_matrices(m: int, k: int, n: int):\n",
    "    A = np.random.uniform(-1, 1, size=(m, k)).astype(np.float32)\n",
    "    B = np.random.uniform(-1, 1, size=(k, n)).astype(np.float32)\n",
    "    return (A, B)\n",
    "\n",
    "# Dimensions of matrices\n",
    "m = 37000\n",
    "k = 23000\n",
    "n = 18000\n",
    "\n",
    "# some magic numbers, just to make calculation heavier\n",
    "sqrt2 = 1.414\n",
    "pi = 3.1415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37000, 23000)\n",
      "(23000, 18000)\n"
     ]
    }
   ],
   "source": [
    "A, B = generate_matrices(m, k, n)\n",
    "print(A.shape)\n",
    "print(B.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_A = A.copy()\n",
    "np_B = B.copy()\n",
    "\n",
    "t0 = time.time()\n",
    "np_A = np.log(np_A + sqrt2)\n",
    "np_B *= pi\n",
    "np_C = np.dot(np_A, np_B)\n",
    "np_C = np.mean(np_C, axis=0)\n",
    "np_C_norm = np_C / np.linalg.norm(np_C)\n",
    "\n",
    "t1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "[ 0.00454275  0.00314037 -0.00701416 ...  0.00196507  0.00404032\n",
      " -0.001335  ]\n",
      "74.277sec\n"
     ]
    }
   ],
   "source": [
    "print(len(np_C_norm))\n",
    "print(np_C_norm)\n",
    "print(f'{(t1 - t0):,.03f}sec')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GPU info...\n",
      "Model:  NVIDIA GeForce RTX 3060\n",
      "Memory: 12.6GB\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "print('Checking GPU info...')\n",
    "if cp.cuda.is_available():\n",
    "    device_id = cp.cuda.runtime.getDevice()\n",
    "    device_properties = cp.cuda.runtime.getDeviceProperties(device_id)\n",
    "    print(f\"Model:  {device_properties['name'].decode()}\")\n",
    "    print(f\"Memory: {device_properties['totalGlobalMem']/1e9:.1f}GB\")\n",
    "else:\n",
    "    raise RuntimeError('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# Move data from main memory to GPU memory\n",
    "cp_A = cp.asarray(A)\n",
    "cp_B = cp.asarray(B)\n",
    "\n",
    "t1 = time.time()\n",
    "# Calculation\n",
    "cp_A = cp.log(cp_A + sqrt2)\n",
    "cp_B = cp_B / pi\n",
    "cp_C = cp.dot(cp_A, cp_B) \n",
    "cp_C = np.mean(cp_C, axis=0)\n",
    "cp_C_norm = cp_C / cp.linalg.norm(cp_C)\n",
    "\n",
    "t2 = time.time()\n",
    "# Move data from GPU memory back to CPU memory\n",
    "np_C_norm2 = cp.asnumpy(cp_C_norm)\n",
    "\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "[ 0.00454276  0.00314038 -0.00701416 ...  0.00196508  0.00404033\n",
      " -0.001335  ]\n",
      "Move data from main memory to GPU memory: 2.400sec\n",
      "Calculation:                              3.472sec\n",
      "Move data from GPU memory to main memory: 0.000sec\n",
      "=====\n",
      "Total:                                    5.872sec\n"
     ]
    }
   ],
   "source": [
    "print(len(np_C_norm2))\n",
    "print(np_C_norm2)\n",
    "print(f'Move data from main memory to GPU memory: {(t1 - t0):,.3f}sec')\n",
    "print(f'Calculation:                              {(t2 - t1):,.3f}sec')\n",
    "print(f'Move data from GPU memory to main memory: {(t3 - t2):,.3f}sec')\n",
    "print('=====')\n",
    "print(f'Total:                                    {(t3 - t0):,.3f}sec')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results consistency verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolerance = 1e-7\n",
    "np.allclose(np_C_norm, np_C_norm2, atol=tolerance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More results\n",
    "\n",
    "| m\\*n\\*k       | cuBLAS      | OpenBLAS    | CuPy       | NumPy      |\n",
    "| ------------- | ----------- | ----------- | ---------- | ---------- |\n",
    "| 3k\\*1k\\*2k    | 104.2ms     | 46.8ms      | 172.8ms    | 44.7ms     |\n",
    "| 8k\\*2k\\*3k    | 132.3ms     | 315.6ms     | 267.5ms    | 300.2ms    |\n",
    "| 17k\\*4k\\*6k   | 0.361s      | 2.292s      | 0.596s     | 2.165s     |\n",
    "| 25k\\*6k\\*8k   | 0.631s      | 6.486s      | 1.111s     | 6.108s     |\n",
    "| 30k\\*8k\\*11k  | 1.145s      | 13.847s     | 1.704s     | 13.336s    |\n",
    "| 50k\\*9k\\*13k  | 2.097s      | 30.249s     | 3.279s     | 28.735s    |\n",
    "| 77k\\*12k\\*23k | 6.336s      | 106.817s    | [OOM]      | [OOM]      |\n",
    "\n",
    "Notes:\n",
    "* OpenBLAS is the typical linear algebra library internally used by NumPy.\n",
    "* cuBLAS is CuPy's equivalent implemented in C."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
